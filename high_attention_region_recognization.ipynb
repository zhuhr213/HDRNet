{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from utils.gen_bert_embedding import circRNABert, seq2kmer_bert\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "from utils.HDRNet import *\n",
    "from utils.utils import *\n",
    "\n",
    "def seq2kmer_bert(seq, k):\n",
    "    seq_length = len(seq)\n",
    "    import random\n",
    "    kmer = [seq[x:x + k] for x in range(seq_length - k + 1)]\n",
    "    kmers = \" \".join(kmer)\n",
    "    return kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 101\n",
    "\n",
    "filename = 'TIA1_Hela.tsv'\n",
    "\n",
    "name, sequences, structs, label = read_csv_with_name('dataset/' + filename)\n",
    "\n",
    "# name = list(name)\n",
    "\n",
    "# sequences = list(sequences)\n",
    "\n",
    "index = [1998, 2, 13]  # Samples be plotted\n",
    "name = name[index]\n",
    "sequences = sequences[index]\n",
    "structs = structs[index]\n",
    "label = label[index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./BERT_Model/ were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "structure = np.zeros((len(structs), 1, max_length))  # (N, 1, 101)\n",
    "for i in range(len(structs)):\n",
    "    struct = structs[i].split(',')\n",
    "    ti = [float(t) for t in struct]\n",
    "    ti = np.array(ti).reshape(1, -1)\n",
    "    structure[i] = np.concatenate([ti], axis=0)\n",
    "\n",
    "# Generate bert embedding\n",
    "model__path = './BERT_Model/'  \n",
    "tokenizer = BertTokenizer.from_pretrained(model__path, do_lower_case=False)\n",
    "model = BertModel.from_pretrained(model__path)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "# model = torch.nn.DataParallel(model, device_ids=[0, 1, 2, 3])\n",
    "model = model.eval()\n",
    "\n",
    "\n",
    "bert_embedding = circRNABert(sequences, model, tokenizer, device, 3)  # default k=3  # (N, 101, 768)\n",
    "bert_embedding = bert_embedding.transpose([0, 2, 1])  # (N, 768, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 768, 99)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HDRNet(\n",
       "  (conv0): Conv1d(\n",
       "    (conv): Conv1d(768, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv1): Conv1d(\n",
       "    (conv): Conv1d(1, 128, kernel_size=(3,), stride=(1,), bias=False)\n",
       "    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (multiscale_str): multiscale(\n",
       "    (conv0): Conv1d(\n",
       "      (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1d(\n",
       "        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv1d(\n",
       "        (conv): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv1d(\n",
       "        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv1d(\n",
       "        (conv): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv1d(\n",
       "        (conv): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv1d(\n",
       "        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv1d(\n",
       "        (conv): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv1d(\n",
       "        (conv): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Conv1d(\n",
       "        (conv): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (multiscale_bert): multiscale(\n",
       "    (conv0): Conv1d(\n",
       "      (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1d(\n",
       "        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv1d(\n",
       "        (conv): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv1d(\n",
       "        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv1d(\n",
       "        (conv): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv1d(\n",
       "        (conv): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv1d(\n",
       "        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv1d(\n",
       "        (conv): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv1d(\n",
       "        (conv): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Conv1d(\n",
       "        (conv): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "        (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dpcnn): DPCNN(\n",
       "    (conv): Conv1d(\n",
       "      (conv): Conv1d(256, 256, kernel_size=(5,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv1): Conv1d(\n",
       "      (conv): Conv1d(256, 256, kernel_size=(5,), stride=(1,), bias=False)\n",
       "      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (pooling): MaxPool1d(kernel_size=(3,), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (padding_conv): ConstantPad1d(padding=(2, 2), value=0)\n",
       "    (padding_pool): ConstantPad1d(padding=(0, 1), value=0)\n",
       "    (DPCNNblocklist): ModuleList(\n",
       "      (0-5): 6 x DPCNNblock(\n",
       "        (conv): Conv1d(\n",
       "          (conv): Conv1d(256, 256, kernel_size=(5,), stride=(1,), bias=False)\n",
       "          (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv1): Conv1d(\n",
       "          (conv): Conv1d(256, 256, kernel_size=(5,), stride=(1,), bias=False)\n",
       "          (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (max_pooling): MaxPool1d(kernel_size=(3,), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (padding_conv): ConstantPad1d(padding=(2, 2), value=0)\n",
       "        (padding_pool): ConstantPad1d(padding=(0, 1), value=0)\n",
       "      )\n",
       "    )\n",
       "    (classifier): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HDRNet().to(device)\n",
    "\n",
    "# modelname = filename.replace('K562', 'HepG2')\n",
    "# modelname = filename.replace('HepG2', 'K562')  # For dynamic prediction\n",
    "model_file = 'results/model/' + filename.rstrip('.tsv') + '.pth'\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9990],\n",
       "        [1.0000],\n",
       "        [0.9979]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = torch.sigmoid(model(torch.tensor(bert_embedding).to(device).float(), torch.tensor(structure).to(device).float()))\n",
    "prob  # See binding predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "torch.cuda.empty_cache()\n",
    "test_emb = torch.tensor(bert_embedding).requires_grad_().to(device).type(torch.float32)\n",
    "test_struc = torch.tensor(structure).requires_grad_().to(device).type(torch.float32)\n",
    "# print(test_emb)\n",
    "e = shap.GradientExplainer(model, [test_emb, test_struc])\n",
    "\n",
    "i=1 # First see the 0-th sample\n",
    "shap_values = e.shap_values([test_emb[i:i+1], test_struc[i:i+1]])\n",
    "\n",
    "def norm(data):\n",
    "    _range = np.max(data,axis=1) - np.min(data, axis=1)\n",
    "    return (data - np.min(data,axis=1)) / _range\n",
    "\n",
    "# sss = seq2kmer_bert(test_seq[i], 3).split(' ')\n",
    "\n",
    "input_seq = sequences[i]\n",
    "input_struct = test_struc[i]\n",
    "\n",
    "# bert_gradient_data = norm(shap_values[0]) #[1, 768, 99]\n",
    "# bert_gradient_data = np.exp(shap_values[0])\n",
    "\n",
    "bert_attention_data = np.max(shap_values[0], axis=1)  # [1,99]  \n",
    "bert_attention_data = np.insert(bert_attention_data, 0, values=0, axis=1)\n",
    "bert_attention_data = np.insert(bert_attention_data, bert_attention_data.shape[-1], values=0, axis=1)\n",
    "bert_attention_data = convert_one_hot2([input_seq], bert_attention_data[0,:]).transpose(1,0,2).squeeze()\n",
    "\n",
    "struc_attention_data = shap_values[1][0]\n",
    "# (shap_values[1][0]-np.min(shap_values[1][0]))/(np.max(shap_values[1][0])-np.min(shap_values[1][0]))\n",
    "\n",
    "W = np.concatenate([bert_attention_data, struc_attention_data], axis=0)\n",
    "\n",
    "x_str = input_struct.cpu().detach().numpy().reshape(101, 1)\n",
    "str_null = np.zeros_like(x_str)\n",
    "ind =np.where(x_str == -1)[0]\n",
    "str_null[ind,0]=1\n",
    "str_null=np.squeeze(str_null).T\n",
    "\n",
    "\n",
    "onehot = convert_one_hot([input_seq]).squeeze()\n",
    "\n",
    "X = np.concatenate([onehot, input_struct.cpu().detach().numpy()], axis=0)\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(data) #, columns=sss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the salience map of the selected sample\n",
    "import utils.visualize as visualize\n",
    "visualize.plot_saliency(X, W, nt_width=100, norm_factor=3, str_null=str_null, outdir=\"results/high_attention_region_plot/out.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the salience map\n",
    "![pic_salience_map](./results/high_attention_region_plot/out.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('graph-bert')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b6bc36ae4bc4d7e7d3fbbfe91bd00d644eb04fda392dd3dae0e564915faaa43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
